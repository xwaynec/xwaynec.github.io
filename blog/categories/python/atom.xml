<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Python | Wayne-WH.Chen Blog]]></title>
  <link href="http://xwaynec.github.io/blog/categories/python/atom.xml" rel="self"/>
  <link href="http://xwaynec.github.io/"/>
  <updated>2016-02-15T12:39:40+08:00</updated>
  <id>http://xwaynec.github.io/</id>
  <author>
    <name><![CDATA[xwaynec]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[PyCharm with pyspark and mysql]]></title>
    <link href="http://xwaynec.github.io/blog/2015/12/28/pycharm-with-pyspark-and-mysql/"/>
    <updated>2015-12-28T21:19:55+08:00</updated>
    <id>http://xwaynec.github.io/blog/2015/12/28/pycharm-with-pyspark-and-mysql</id>
    <content type="html"><![CDATA[<p>最近需要來研究一下 Spark ，看了一下API的部分有 Java, Scala, Python, R，個人是略懂 Python，只好來踩雷一下。公司的專案是 Rails + MySql，若要做資料分析，目前暫時想拿來嘗試的方案是透過 Spark 去取得 MySql 資料。
按照官網的介紹把整包抓下來之後，進入目錄裡面：</p>

<p><code>bash
./bin/pyspark
</code></p>

<p>打完指令，Python 的 shell 就會出現。</p>

<p>```
Welcome to</p>

<pre><code>  ____              __
 / __/__  ___ _____/ /__
_\ \/ _ \/ _ `/ __/  '_/
</code></pre>

<p>   /<strong> / .</strong>/_,<em>/</em>/ /_/_\   version 1.6.0</p>

<pre><code>  /_/
</code></pre>

<p>Using Python version 2.7.11 (default, Dec  5 2015 14:44:53)
SparkContext available as sc, HiveContext available as sqlContext.</p>

<blockquote><blockquote><blockquote><p>```
但是其實卡雷比較久的是，我比較想要用 IDE 去寫code&hellip;雖然說用 ipython 也可以，不過有些函式庫可以提示比較high&hellip;。</p></blockquote></blockquote></blockquote>

<p>以下為踩雷後的紀錄流程，首先你要先有一台 macbook&hellip;</p>

<h3>1. 需要先去 MySql 官網下載</h3>

<p><a href="https://dev.mysql.com/downloads/connector/j/3.1.html">JDBC driver</a></p>

<h3>2. 打開 PyCharm &ndash;> Preference &ndash;> Project interpreters</h3>

<p>選擇 <code>Show paths for the selected interpreters</code>，點選 <code>+</code> 加入這邊兩個 lib path。
  * <code>spark-1.6.0 path</code>/python
  * <code>spark-1.6.0 path</code>/python/lib/py4j-0.9-src.zip</p>

<p>接下來在 python file import pyspark 相關的lib就不會有錯。</p>

<p><code>python
from pyspark import SparkContext
from pyspark.sql import SQLContext
</code></p>

<h3>3. 在 Spark-1.6 Project 當中</h3>

<p><code>bash
mv conf/spark-defaults.conf.template conf/spark-defaults.conf
</code></p>

<p>接下來加入兩組設定</p>

<p><code>
spark.executor.extraClassPath   &lt;Project Path&gt;/mysql-connector-java-5.1.38-bin.jar
spark.driver.extraClassPath   &lt;Project Path&gt;/mysql-connector-java-5.1.38-bin.jar
</code></p>

<h3>4. 接下來在 PyCharm &ndash;> Run &ndash;> Edit Configuration，Environment variables 加入以下:</h3>

<ul>
<li>SPARK_HOME  <code>spark-1.6.0 path</code></li>
<li>PYTHONPATH  $SPARK_HOME/python/lib/py4j-0.9-src.zip:$PYTHONPATH</li>
</ul>


<h3>5. 測試一下是否可以連線 MySql</h3>

<p><code>python
sc = SparkContext()
sqlctx = SQLContext(sc)
df = sqlctx.load(
  source='jdbc',
  driver='com.mysql.jdbc.Driver',
  url='jdbc:mysql://localhost/database_name?user={qwert}&amp;password={qwert}',
  dbtable='table_name')
print df.take(2)  
</code></p>
]]></content>
  </entry>
  
</feed>
